{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdbe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rlcard\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b520b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cards = ['SA','S2','S3','S4','S5','S6','S7','S8','S9','ST','SJ','SQ','SK',\n",
    "             'HA','H2','H3','H4','H5','H6','H7','H8','H9','HT','HJ','HQ','HK',\n",
    "             'CA','C2','C3','C4','C5','C6','C7','C8','C9','CT','CJ','CQ','CK',\n",
    "             'DA','D2','D3','D4','D5','D6','D7','D8','D9','DT','DJ','DQ','DK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89eb8cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackjackEnv(gym.Env):\n",
    "    \"\"\"Wraps Blackjack as an OpenAI Gym environment.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Defines Action and Observation Spaces for the environment\"\"\"\n",
    "        self._rlcard_env = rlcard.make('blackjack')\n",
    "        self.action_space = gym.spaces.Discrete(self._rlcard_env.num_actions)\n",
    "        self.observation_space = gym.spaces.Box(0, 31, shape=self._rlcard_env.state_shape[0], dtype=np.int32)\n",
    "\n",
    "    def seed(self, seed):\n",
    "        \"\"\"Seed for generation of random behavior.\"\"\"\n",
    "        self._rlcard_env.seed(seed)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment to an initial state and returns the initial observation.\"\"\"\n",
    "        all_obs, _ = self._rlcard_env.reset()\n",
    "        obs = tuple(all_obs[\"obs\"].tolist())\n",
    "        player0_hand = all_obs[\"raw_obs\"][\"player0 hand\"]\n",
    "        dealer_hand = all_obs[\"raw_obs\"][\"dealer hand\"]\n",
    "        unknown_card_list = [card for card in all_cards if card not in player0_hand+dealer_hand]\n",
    "        \n",
    "        return obs, player0_hand, dealer_hand, unknown_card_list\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Run one timestep of the environment's dynamics.\n",
    "        \n",
    "        Args:\n",
    "            action: an action provided by the agent\n",
    "        \n",
    "        Returns:\n",
    "            observation: an observation provided by the environment\n",
    "            reward (float): the reward returned as a result of taking the action\n",
    "            terminated (bool): whether a terminal state is reached\n",
    "            info (dictionary): an empty dictionary to conform to gym.Env        \n",
    "        \"\"\"\n",
    "        all_obs, _ = self._rlcard_env.step(action)\n",
    "        obs = tuple(all_obs[\"obs\"].tolist())\n",
    "        player0_hand = all_obs[\"raw_obs\"][\"player0 hand\"]\n",
    "        dealer_hand = all_obs[\"raw_obs\"][\"dealer hand\"]\n",
    "        unknown_card_list = [card for card in all_cards if card not in player0_hand+dealer_hand]\n",
    "        done = False\n",
    "        reward = 0.0\n",
    "        if self._rlcard_env.is_over():\n",
    "            done = True\n",
    "            reward = float(self._rlcard_env.get_payoffs()[0])\n",
    "        return obs, player0_hand, dealer_hand, unknown_card_list, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d352e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank2score = {\"A\":11, \"2\":2, \"3\":3, \"4\":4, \"5\":5, \"6\":6, \"7\":7, \"8\":8, \"9\":9, \"T\":10, \"J\":10, \"Q\":10, \"K\":10}\n",
    "def get_score(hand):\n",
    "    score = 0\n",
    "    count_a = 0\n",
    "    for card in hand:\n",
    "        score += rank2score[card[1:]]\n",
    "        if card[1] == 'A':\n",
    "            count_a += 1\n",
    "    while score > 21 and count_a > 0:\n",
    "        count_a -= 1\n",
    "        score -= 10\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0346fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player0_hit_card(player0_hand, remain_card_list): \n",
    "    now_player0_hand = player0_hand.copy()\n",
    "    now_remain_card_list = remain_card_list.copy()\n",
    "    \n",
    "    card = random.choice(now_remain_card_list)\n",
    "    now_remain_card_list.remove(card)\n",
    "    now_player0_hand.append(card)\n",
    "    now_player0_score = get_score(now_player0_hand)\n",
    "    return now_player0_score, now_remain_card_list\n",
    "    \n",
    "def dealer_draw_card(dealer_score, hidden, dealer_hand, remain_card_list):\n",
    "    now_dealer_hand = dealer_hand.copy()\n",
    "    now_remain_card_list = remain_card_list.copy()\n",
    "    now_dealer_score = dealer_score\n",
    "    while now_dealer_score<17:\n",
    "        #dealer draws\n",
    "        card = random.choice(now_remain_card_list)\n",
    "        now_remain_card_list.remove(card)\n",
    "        now_dealer_hand.append(card)\n",
    "        now_dealer_score = get_score(now_dealer_hand + [hidden])\n",
    "    return now_dealer_score\n",
    "\n",
    "def policy(obs, player0_hand, dealer_hand, unknown_card_list, trials =1000): \n",
    "    assert obs[0]<=21\n",
    "    \n",
    "#     if obs[0]<17:      \n",
    "        \n",
    "    player0_hit_wintie_trials = 0\n",
    "    player0_stand_wintie_trials = 0\n",
    "    #loop for all unknown cards as hidden card in dealer's hand\n",
    "    for hidden in unknown_card_list:\n",
    "        dealer_score = get_score(dealer_hand+[hidden])\n",
    "        remain_card_list = [card for card in unknown_card_list if card != hidden] \n",
    "        if dealer_score >= 17:\n",
    "            # if the dealer already >=17, directly compare the score\n",
    "            #hit win trials\n",
    "            for _ in range(trials):\n",
    "                now_player0_score, _ = player0_hit_card(player0_hand, remain_card_list)\n",
    "                if now_player0_score<=21 and now_player0_score>=dealer_score:\n",
    "                    player0_hit_wintie_trials += 1\n",
    "\n",
    "            #stand win trials\n",
    "            if obs[0]>= dealer_score:\n",
    "                player0_stand_wintie_trials += trials\n",
    "\n",
    "        else:\n",
    "            #if the dealer <17, still need to draw\n",
    "            #hit win trials\n",
    "            for _ in range(trials):\n",
    "                player0_score, now_remain_card_list = player0_hit_card(player0_hand, remain_card_list)\n",
    "                # if player0 >21, bust and pass\n",
    "                if player0_score>21: \n",
    "                    continue\n",
    "                else:\n",
    "                    dealer_score_after_draw = dealer_draw_card(dealer_score, hidden, dealer_hand, now_remain_card_list)\n",
    "                    if dealer_score_after_draw >21: #dealer busts\n",
    "                         player0_hit_wintie_trials += 1\n",
    "                    else: #dealer doesn't bust but small than player\n",
    "                        if dealer_score_after_draw<=player0_score:\n",
    "                            player0_hit_wintie_trials += 1\n",
    "\n",
    "            #stand win trials\n",
    "            for _ in range(trials):\n",
    "                dealer_score_after_draw = dealer_draw_card(dealer_score, hidden, dealer_hand, remain_card_list)\n",
    "                if dealer_score_after_draw >21:\n",
    "                     player0_stand_wintie_trials += 1\n",
    "                else:\n",
    "                    if dealer_score_after_draw<=obs[0]:\n",
    "                        player0_stand_wintie_trials += 1\n",
    "        \n",
    "    if player0_hit_wintie_trials>player0_stand_wintie_trials:\n",
    "        return 'hit'\n",
    "    else: return 'stand'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1655139",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlackjackEnv()\n",
    "actions = {'hit':0, 'stand':1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d4c311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 1000/1000 [00:05<00:00, 184.75it/s, mean reward=-.079]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 188.39it/s, mean reward=-.075]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 190.14it/s, mean reward=-.054]\n",
      "100%|████████████████████| 1000/1000 [00:05<00:00, 190.32it/s, mean reward=-.07]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 191.54it/s, mean reward=-.064]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 190.98it/s, mean reward=-.039]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 191.95it/s, mean reward=-.055]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 189.11it/s, mean reward=-.022]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 192.91it/s, mean reward=-.042]\n",
      "100%|███████████████████| 1000/1000 [00:05<00:00, 190.42it/s, mean reward=-.094]\n"
     ]
    }
   ],
   "source": [
    "mean_reward_list_10 = []\n",
    "# 10 trials\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = policy(obs, player0_hand, dealer_hand, unknown_card_list, trials=10)\n",
    "                action = actions[action]\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_reward_list_10.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "252b6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.059399999999999994\n",
      "0.020308618859981593\n"
     ]
    }
   ],
   "source": [
    "mean_reward_10 = np.array(mean_reward_list_10)\n",
    "print(mean_reward_10.mean())\n",
    "print(mean_reward_10.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0b0f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.38it/s, mean reward=-.048]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.96it/s, mean reward=-.004]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.15it/s, mean reward=-.064]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.50it/s, mean reward=-.068]\n",
      "100%|████████████████████| 1000/1000 [00:18<00:00, 52.86it/s, mean reward=-.041]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 50.55it/s, mean reward=-.081]\n",
      "100%|████████████████████| 1000/1000 [00:18<00:00, 52.80it/s, mean reward=-.069]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.88it/s, mean reward=-.057]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 51.75it/s, mean reward=-.036]\n",
      "100%|████████████████████| 1000/1000 [00:19<00:00, 52.32it/s, mean reward=-.047]\n"
     ]
    }
   ],
   "source": [
    "mean_reward_list_50 = []\n",
    "# 50 trials\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = policy(obs, player0_hand, dealer_hand, unknown_card_list, trials=50)\n",
    "                action = actions[action]\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_reward_list_50.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "834ad270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.051500000000000004\n",
      "0.020674863965695157\n"
     ]
    }
   ],
   "source": [
    "mean_reward_50 = np.array(mean_reward_list_50)\n",
    "print(mean_reward_50.mean())\n",
    "print(mean_reward_50.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "941879f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 1000/1000 [00:36<00:00, 27.58it/s, mean reward=-.023]\n",
      "100%|████████████████████| 1000/1000 [00:37<00:00, 26.80it/s, mean reward=-.061]\n",
      "100%|████████████████████| 1000/1000 [00:36<00:00, 27.68it/s, mean reward=-.068]\n",
      "100%|████████████████████| 1000/1000 [00:37<00:00, 26.85it/s, mean reward=-.073]\n",
      "100%|████████████████████| 1000/1000 [00:37<00:00, 26.91it/s, mean reward=-.032]\n",
      "100%|████████████████████| 1000/1000 [00:35<00:00, 28.08it/s, mean reward=-.072]\n",
      "100%|████████████████████| 1000/1000 [00:35<00:00, 28.10it/s, mean reward=-.044]\n",
      "100%|████████████████████| 1000/1000 [00:36<00:00, 27.24it/s, mean reward=0.014]\n",
      "100%|████████████████████| 1000/1000 [00:35<00:00, 27.96it/s, mean reward=-.022]\n",
      "100%|████████████████████| 1000/1000 [00:37<00:00, 26.92it/s, mean reward=-.029]\n"
     ]
    }
   ],
   "source": [
    "mean_reward_list_100 = []\n",
    "# 100 trials\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = policy(obs, player0_hand, dealer_hand, unknown_card_list, trials=100)\n",
    "                action = actions[action]\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_reward_list_100.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7137fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.041\n",
      "0.026566896694947266\n"
     ]
    }
   ],
   "source": [
    "mean_reward_100 = np.array(mean_reward_list_100)\n",
    "print(mean_reward_100.mean())\n",
    "print(mean_reward_100.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49bddb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 1000/1000 [02:55<00:00,  5.70it/s, mean reward=-.019]\n",
      "100%|████████████████████| 1000/1000 [02:51<00:00,  5.83it/s, mean reward=-.054]\n",
      "100%|████████████████████| 1000/1000 [02:50<00:00,  5.85it/s, mean reward=-.083]\n",
      "100%|████████████████████| 1000/1000 [02:50<00:00,  5.88it/s, mean reward=-.049]\n",
      "100%|████████████████████| 1000/1000 [02:54<00:00,  5.74it/s, mean reward=-.055]\n",
      "100%|████████████████████| 1000/1000 [02:54<00:00,  5.73it/s, mean reward=-.035]\n",
      "100%|████████████████████| 1000/1000 [02:47<00:00,  5.95it/s, mean reward=-.033]\n",
      "100%|█████████████████████| 1000/1000 [02:53<00:00,  5.76it/s, mean reward=-.07]\n",
      "100%|████████████████████| 1000/1000 [02:55<00:00,  5.69it/s, mean reward=-.033]\n",
      "100%|████████████████████| 1000/1000 [02:53<00:00,  5.78it/s, mean reward=-.047]\n"
     ]
    }
   ],
   "source": [
    "# 500 trials\n",
    "mean_reward_list_500 = []\n",
    "# 100 trials\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = policy(obs, player0_hand, dealer_hand, unknown_card_list, trials=500)\n",
    "                action = actions[action]\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_reward_list_500.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a8c00b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0478\n",
      "0.018043281298034456\n"
     ]
    }
   ],
   "source": [
    "mean_reward_500 = np.array(mean_reward_list_500)\n",
    "print(mean_reward_500.mean())\n",
    "print(mean_reward_500.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b30d5018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 1000/1000 [05:52<00:00,  2.84it/s, mean reward=-.052]\n",
      "100%|████████████████████| 1000/1000 [05:43<00:00,  2.91it/s, mean reward=-.018]\n",
      "100%|████████████████████| 1000/1000 [05:44<00:00,  2.90it/s, mean reward=0.003]\n",
      "100%|████████████████████| 1000/1000 [05:38<00:00,  2.95it/s, mean reward=-.035]\n",
      "100%|████████████████████| 1000/1000 [05:39<00:00,  2.94it/s, mean reward=-.072]\n",
      "100%|████████████████████| 1000/1000 [05:44<00:00,  2.90it/s, mean reward=-.105]\n",
      "100%|████████████████████| 1000/1000 [05:45<00:00,  2.89it/s, mean reward=-.062]\n",
      "100%|████████████████████| 1000/1000 [05:42<00:00,  2.92it/s, mean reward=0.037]\n",
      "100%|████████████████████| 1000/1000 [05:35<00:00,  2.98it/s, mean reward=-.075]\n",
      "100%|████████████████████| 1000/1000 [05:39<00:00,  2.94it/s, mean reward=-.051]\n"
     ]
    }
   ],
   "source": [
    "# 1000 trials\n",
    "mean_reward_list_1000 = []\n",
    "# 100 trials\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = policy(obs, player0_hand, dealer_hand, unknown_card_list, trials=1000)\n",
    "                action = actions[action]\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_reward_list_1000.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "989e863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.043\n",
      "0.03926830783214372\n"
     ]
    }
   ],
   "source": [
    "mean_reward_1000 = np.array(mean_reward_list_1000)\n",
    "print(mean_reward_1000.mean())\n",
    "print(mean_reward_1000.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_policy(dealer_hand, player0_hand):\n",
    "    \n",
    "    if get_score(player0_hand) == 21:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    dealer_dim = ['2','3','4','5','6','7','8','9','T','J','Q','K','A']\n",
    "    hard_dim = [i for i in range(20, 3, -1)] #[20~4]\n",
    "    soft_dim = [i for i in range(21, 1, -1)] #[21~2]\n",
    "    \n",
    "    hard_chart = 1-np.array(\n",
    "        [\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,1,1,1,1,1,1,1,1],\n",
    "         [0,0,0,0,0,1,1,1,1,1,1,1,1],\n",
    "         [0,0,0,0,0,1,1,1,1,1,1,1,1],\n",
    "         [0,0,0,0,0,1,1,1,1,1,1,1,1],\n",
    "         [1,1,0,0,0,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1]])\n",
    "    soft_chart = 1-np.array(\n",
    "        [[0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "         [0,0,0,0,0,0,0,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "         [1,1,1,1,1,1,1,1,1,1,1,1,1],])\n",
    "    \n",
    "    has_A = False\n",
    "    no_A_hand = player0_hand.copy()\n",
    "    for card in player0_hand:\n",
    "        if card[1] == 'A':\n",
    "            has_A = True\n",
    "            no_A_hand.remove(card)\n",
    "            break\n",
    "            \n",
    "    dealer_index = dealer_dim.index(dealer_hand[0][1])\n",
    "    \n",
    "    if has_A:\n",
    "        soft_score = int(get_score(no_A_hand))\n",
    "        soft_index = soft_dim.index(soft_score)\n",
    "        \n",
    "        action = soft_chart[soft_index, dealer_index]\n",
    "    else:\n",
    "        hard_score = int(get_score(player0_hand))\n",
    "        hard_index = hard_dim.index(hard_score)\n",
    "        action = hard_chart[hard_index, dealer_index]\n",
    "    \n",
    "    return action\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be4a5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 1000/1000 [00:02<00:00, 345.06it/s, mean reward=-.012]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 346.83it/s, mean reward=-.033]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 348.32it/s, mean reward=-.015]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 338.65it/s, mean reward=-.098]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 338.09it/s, mean reward=-.052]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 347.09it/s, mean reward=-.028]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 341.22it/s, mean reward=-.034]\n",
      "100%|████████████████████| 1000/1000 [00:02<00:00, 344.32it/s, mean reward=-.02]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 342.13it/s, mean reward=0.003]\n",
      "100%|███████████████████| 1000/1000 [00:02<00:00, 339.31it/s, mean reward=-.076]\n"
     ]
    }
   ],
   "source": [
    "mean_chart_reward_list = []\n",
    "for j in range(10):\n",
    "    reward_list = []\n",
    "    with tqdm(range(1000)) as tbar:\n",
    "        for _ in tbar:\n",
    "            obs, player0_hand, dealer_hand, unknown_card_list = env.reset()\n",
    "            while True:\n",
    "                action = chart_policy(dealer_hand, player0_hand)\n",
    "                obs, player0_hand, dealer_hand, unknown_card_list, reward, done, _ = env.step(action)\n",
    "                if done:\n",
    "                    reward_list.append(reward)\n",
    "                    tbar.set_postfix({'mean reward':sum(reward_list)/len(reward_list)})\n",
    "                    break\n",
    "    mean_chart_reward_list.append(sum(reward_list)/len(reward_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ddae314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.036500000000000005\n",
      "0.029272000273298713\n"
     ]
    }
   ],
   "source": [
    "mean_chart_reward = np.array(mean_chart_reward_list)\n",
    "print(mean_chart_reward.mean())\n",
    "print(mean_chart_reward.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
